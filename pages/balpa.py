import streamlit as st
import folium
from streamlit_folium import st_folium
import ezdxf
from pyproj import Geod, Transformer
import io
import os
import json
import base64
import pandas as pd
import re
import google.generativeai as genai
from datetime import datetime

# Gemini AI ì„¤ì •
try:
    GENAI_API_KEY = st.secrets["GENAI_API_KEY"]
    genai.configure(api_key=GENAI_API_KEY)
    GEMINI_MODEL = genai.GenerativeModel("models/gemini-2.5-flash-preview-05-20")
    AI_AVAILABLE = True
except:
    st.warning("âš ï¸ Gemini AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secretsì— GENAI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    AI_AVAILABLE = False

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="GIS/CAD ë·°ì–´",
    page_icon="ğŸ—ºï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë°œíŒŒë°ì´í„° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
BLAST_EXTRACTION_PROMPT = '''
# INSTRUCTION
- ë°˜ë“œì‹œ ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼ ì˜¤ì§ TSV(íƒ­ êµ¬ë¶„) ë°ì´í„°ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
- ì„¤ëª…, ë§ˆí¬ë‹¤ìš´, ì½”ë“œë¸”ë¡, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ì•„ë˜ ì˜ˆì‹œì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
ë°œíŒŒì¼ì	ë°œíŒŒì‹œê°„	ì§€ë°œë‹¹ì¥ì•½ëŸ‰(ìµœì†Œ, kg)	ì§€ë°œë‹¹ì¥ì•½ëŸ‰(ìµœëŒ€, kg)	í­ì•½ì‚¬ìš©ëŸ‰(kg)	ë°œíŒŒì§„ë™(cm/sec)	ë°œíŒŒì†ŒìŒ(dB(A))	ê³„ì¸¡ìœ„ì¹˜	ë¹„ê³ 
2023-07-27	08:05	0.5	0.9	73	-	-	-	PLA-2
2023-07-27	13:47	0.4	0.8	77	0.87	53.29	í‹°ìŠ¤í…Œì´ì…˜	PD-2
2023-07-27	13:47	-	-	-	0.71	61.23	ì–‘ë§ì§‘	PD-2
(ìœ„ ì˜ˆì‹œëŠ” í˜•ì‹ë§Œ ì°¸ê³ , ì‹¤ì œ ë°ì´í„°ëŠ” ì…ë ¥ê°’ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ìƒì„±)
# ì…ë ¥
- ì…ë ¥1: ë°œíŒŒì‘ì—…ì¼ì§€_TSV (ì•„ë˜ì™€ ê°™ì€ í˜•ì‹)
- ì…ë ¥2: ê³„ì¸¡ì¼ì§€_TSV (ì•„ë˜ì™€ ê°™ì€ í˜•ì‹, **ê³„ì¸¡ì¼ì§€ í‘œëŠ” PDF 2í˜ì´ì§€ ì´í›„ë¶€í„° ì¶”ì¶œ**)
# ì…ë ¥1 ì˜ˆì‹œ
ë°œíŒŒì¼ì	ë°œíŒŒì‹œê°„	ì§€ë°œë‹¹ì¥ì•½ëŸ‰(ìµœì†Œ, kg)	ì§€ë°œë‹¹ì¥ì•½ëŸ‰(ìµœëŒ€, kg)	í­ì•½ì‚¬ìš©ëŸ‰(kg)	ë¹„ê³ 
2023-07-27	08:05	0.5	0.9	73	PLA-2
2023-07-27	13:47	0.4	0.8	77	PD-2
# ì…ë ¥2 ì˜ˆì‹œ (**2í˜ì´ì§€ ì´í›„ í‘œë§Œ**)
Date/Time	Peak Particle Vel (X_Axis) (mm/sec)	Peak Particle Vel (Y_Axis) (mm/sec)	Peak Particle Vel (Z_Axis) (mm/sec)	LMax (Sound) (dBA)	ì¸¡ì •ìœ„ì¹˜
2023/07/27 1:47:00 PM	0.71	0.36	0.71	61.23	ì–‘ë§ì§‘
2023/07/27 1:47:00 PM	0.87	0.56	0.87	53.29	í‹°ìŠ¤í…Œì´ì…˜
# Mapping Rules
- ë‘ ì…ë ¥ì„ ë³‘í•©í•˜ì—¬ ìœ„ ì˜ˆì‹œì™€ ë™ì¼í•œ TSVë§Œ ì¶œë ¥
- ì„¤ëª…, ë§ˆí¬ë‹¤ìš´, ì½”ë“œë¸”ë¡, ì£¼ì„, ê¸°íƒ€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ê³„ì¸¡ì¼ì§€ í‘œëŠ” ë°˜ë“œì‹œ PDF 2í˜ì´ì§€ ì´í›„ì˜ í‘œë§Œ ì‚¬ìš© 
- ìµœì¢… í—¤ë”(ê³ ì •ì—´): ë°œíŒŒì¼ì, ë°œíŒŒì‹œê°„, ì§€ë°œë‹¹ì¥ì•½ëŸ‰(ìµœì†Œ, kg), ì§€ë°œë‹¹ì¥ì•½ëŸ‰(ìµœëŒ€, kg), í­ì•½ì‚¬ìš©ëŸ‰(kg), ë°œíŒŒì§„ë™(cm/sec), ë°œíŒŒì†ŒìŒ(dB(A)), ê³„ì¸¡ìœ„ì¹˜, ë¹„ê³ 
- ì •ë ¬: ë°œíŒŒì‹œê°„ ì˜¤ë¦„ì°¨ìˆœ, ê³„ì¸¡ìœ„ì¹˜ ì˜¤ë¦„ì°¨ìˆœ(í•„ìš”ì‹œ)
- ë³‘í•©/ë§¤ì¹­/í¬ë§· ê·œì¹™ì€ ê¸°ì¡´ê³¼ ë™ì¼
'''

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def initialize_session_state():
    if 'blast_dataframe' not in st.session_state:
        st.session_state.blast_dataframe = None
    if 'blast_data_completed' not in st.session_state:
        st.session_state.blast_data_completed = False

# ì•ˆì „í•œ AI ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜
def safe_generate_content(prompt, files=None):
    if not AI_AVAILABLE:
        st.warning("âš ï¸ Gemini AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹¤ì œ êµ¬í˜„ì„ ìœ„í•´ì„œëŠ” API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return None
    try:
        # Gemini AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì‘ë‹µ ë°›ê¸°
        response = GEMINI_MODEL.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"âŒ Gemini AI ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# íŒŒì¼ ë‚´ìš© ì¶”ì¶œ í•¨ìˆ˜
def extract_file_content(file):
    if file.name.endswith('.pdf'):
        if not AI_AVAILABLE:
            st.warning("âš ï¸ PDF íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ì„œëŠ” Gemini AI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return None
        try:
            # PDF íŒŒì¼ì„ Gemini AIì— ì—…ë¡œë“œí•˜ì—¬ ë‚´ìš© ì¶”ì¶œ
            file.seek(0)
            uploaded_file = genai.upload_file(file, mime_type="application/pdf")
            
            filename_lower = file.name.lower()
            is_measurement_file = any(keyword in filename_lower for keyword in ["ê³„ì¸¡", "ì§„ë™", "ì†ŒìŒ"])
            is_blast_log_file = any(keyword in filename_lower for keyword in ["ë°œíŒŒ", "ì‘ì—…", "ì¼ì§€"])

            if is_measurement_file:
                pdf_prompt = """ì´ PDF íŒŒì¼ì€ 'ë°œíŒŒì§„ë™ì†ŒìŒ ê³„ì¸¡ì¼ì§€'ì…ë‹ˆë‹¤. 
                ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ë°ì´í„°ë¥¼ TSV í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
                1. PDF 2í˜ì´ì§€ ì´í›„ì˜ í‘œë§Œ ì¶”ì¶œ
                2. Date/Time, Peak Particle Vel (X_Axis) (mm/sec), Peak Particle Vel (Y_Axis) (mm/sec), 
                   Peak Particle Vel (Z_Axis) (mm/sec), LMax (Sound) (dBA), ì¸¡ì •ìœ„ì¹˜ ì»¬ëŸ¼ í¬í•¨
                3. TSV í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥ (íƒ­ìœ¼ë¡œ êµ¬ë¶„)
                4. ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""
            elif is_blast_log_file:
                pdf_prompt = """ì´ PDF íŒŒì¼ì€ 'ë°œíŒŒì‘ì—…ì¼ì§€'ì…ë‹ˆë‹¤. 
                ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ì£¼ìš” ë°ì´í„°ë¥¼ TSV í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
                1. ë°œíŒŒì¼ì, ë°œíŒŒì‹œê°„, ì§€ë°œë‹¹ì¥ì•½ëŸ‰(ìµœì†Œ, kg), ì§€ë°œë‹¹ì¥ì•½ëŸ‰(ìµœëŒ€, kg), í­ì•½ì‚¬ìš©ëŸ‰(kg), ë¹„ê³  ì»¬ëŸ¼ í¬í•¨
                2. TSV í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥ (íƒ­ìœ¼ë¡œ êµ¬ë¶„)
                3. ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""
            else:
                pdf_prompt = """ì´ PDFì—ì„œ ê°€ì¥ ì¤‘ìš”í•´ ë³´ì´ëŠ” í‘œë¥¼ ì°¾ì•„ TSV í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
                íƒ­ìœ¼ë¡œ êµ¬ë¶„ëœ ë°ì´í„°ë§Œ ì¶œë ¥í•˜ê³ , ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""

            # AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ PDF ë‚´ìš© ì¶”ì¶œ
            response = GEMINI_MODEL.generate_content([pdf_prompt, uploaded_file])
            
            # ì‚¬ìš©ì´ ëë‚œ íŒŒì¼ì€ ì¦‰ì‹œ ì‚­ì œ
            genai.delete_file(uploaded_file.name)

            if response.text:
                return re.sub(r'```tsv|```', '', response.text).strip()
            
            return None

        except Exception as e:
            st.error(f"âŒ {file.name} ì²˜ë¦¬ ì¤‘ AI ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    elif file.name.endswith(('.xlsx', '.xls')):
        try:
            return pd.read_excel(file, engine='openpyxl').to_csv(sep='\t', index=False, encoding='utf-8')
        except Exception as e:
            st.error(f"âŒ ì—‘ì…€ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    return None

# TSV ì‘ë‹µì—ì„œ ë°ì´í„° ì¶”ì¶œ
def extract_tsv_from_response(response_text):
    # TSV ë°ì´í„° ì¶”ì¶œ ë¡œì§
    lines = response_text.strip().split('\n')
    tsv_lines = []
    for line in lines:
        if '\t' in line:  # íƒ­ì´ í¬í•¨ëœ ì¤„ë§Œ TSVë¡œ ê°„ì£¼
            tsv_lines.append(line)
    return '\n'.join(tsv_lines)

# TSVë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ íŒŒì‹±
def parse_tsv_to_dataframe(tsv_text):
    try:
        # TSV ë°ì´í„°ë¥¼ StringIOë¡œ ë³€í™˜í•˜ì—¬ pandasë¡œ ì½ê¸°
        from io import StringIO
        df = pd.read_csv(StringIO(tsv_text), sep='\t', encoding='utf-8')
        return df
    except Exception as e:
        st.error(f"âŒ TSV íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None

# TSV í•„ë“œ ìˆ˜ ìˆ˜ì •
def fix_tsv_field_count(tsv_text):
    lines = tsv_text.strip().split('\n')
    fixed_lines = []
    
    for line in lines:
        fields = line.split('\t')
        # í—¤ë”ëŠ” 9ê°œ í•„ë“œ, ë°ì´í„°ëŠ” 9ê°œ í•„ë“œë¡œ ë§ì¶¤
        if len(fields) < 9:
            fields.extend([''] * (9 - len(fields)))
        elif len(fields) > 9:
            fields = fields[:9]
        fixed_lines.append('\t'.join(fields))
    
    return '\n'.join(fixed_lines)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
initialize_session_state()

# ì œëª©
st.markdown("---")

# ì‚¬ì´ë“œë°”ì— DXF íŒŒì¼ ì—…ë¡œë“œ ì¶”ê°€
st.sidebar.header("ğŸ“ DXF íŒŒì¼ ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("DXF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=['dxf'], key="dxf_uploader")

if uploaded_file is not None:
    # DXF íŒŒì¼ ì²˜ë¦¬
    try:
        # íŒŒì¼ ë‚´ìš©ì„ ë°”ì´íŠ¸ë¡œ ì½ê¸°
        file_content = uploaded_file.read()
        
        # ezdxfë¡œ DXF íŒŒì¼ íŒŒì‹±
        doc = ezdxf.read(io.BytesIO(file_content))
        
        # ì—”í‹°í‹° ì •ë³´ ì¶”ì¶œ
        entities_data = []
        for entity in doc.entitydb.values():
            if hasattr(entity, 'dxftype'):
                entity_info = {
                    'type': entity.dxftype(),
                    'layer': getattr(entity, 'layer', '0'),
                    'color': getattr(entity, 'color', 7),  # 7ì€ í°ìƒ‰
                    'coordinates': []
                }
                
                # ì—”í‹°í‹° íƒ€ì…ë³„ë¡œ ì¢Œí‘œ ì¶”ì¶œ
                if entity.dxftype() == 'LINE':
                    if hasattr(entity, 'dxf') and hasattr(entity.dxf, 'start') and hasattr(entity.dxf, 'end'):
                        entity_info['coordinates'] = [
                            {'x': entity.dxf.start.x, 'y': entity.dxf.start.y},
                            {'x': entity.dxf.end.x, 'y': entity.dxf.end.y}
                        ]
                elif entity.dxftype() in ['LWPOLYLINE', 'POLYLINE']:
                    if hasattr(entity, 'get_points'):
                        points = entity.get_points()
                        entity_info['coordinates'] = [{'x': p[0], 'y': p[1]} for p in points]
                elif entity.dxftype() == 'CIRCLE':
                    if hasattr(entity, 'dxf') and hasattr(entity.dxf, 'center') and hasattr(entity.dxf, 'radius'):
                        entity_info['coordinates'] = [
                            {'x': entity.dxf.center.x, 'y': entity.dxf.center.y},
                            {'radius': entity.dxf.radius}
                        ]
                elif entity.dxftype() in ['TEXT', 'MTEXT']:
                    if hasattr(entity, 'dxf') and hasattr(entity.dxf, 'insert'):
                        entity_info['coordinates'] = [{'x': entity.dxf.insert.x, 'y': entity.dxf.insert.y}]
                        entity_info['text'] = getattr(entity, 'text', getattr(entity, 'text_string', ''))
                
                if entity_info['coordinates']:
                    entities_data.append(entity_info)
        
        # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.dxf_data = {
            'entities': entities_data,
            'filename': uploaded_file.name
        }
        
        st.sidebar.success(f"âœ… {uploaded_file.name} íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
        st.sidebar.info(f"ğŸ“Š ì´ {len(entities_data)}ê°œ ì—”í‹°í‹° ë°œê²¬")
        
        # ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        if st.sidebar.button("ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
            st.sidebar.json(entities_data[:5])  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
        
    except Exception as e:
        st.sidebar.error(f"âŒ DXF íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        st.session_state.dxf_data = None

# HTML íŒŒì¼ ì½ê¸°
def load_html_file():
    try:
        # í˜„ì¬ íŒŒì¼ì´ pages í´ë” ì•ˆì— ìˆìœ¼ë¯€ë¡œ ìƒìœ„ í´ë”ì˜ pages í´ë”ë¡œ ì´ë™
        with open('pages/map.html', 'r', encoding='utf-8') as file:
            return file.read()
    except FileNotFoundError:
        try:
            # ìƒëŒ€ ê²½ë¡œë¡œ ì‹œë„
            with open('../pages/map.html', 'r', encoding='utf-8') as file:
                return file.read()
        except FileNotFoundError:
            try:
                # ì ˆëŒ€ ê²½ë¡œë¡œ ì‹œë„
                current_dir = os.getcwd()
                map_path = os.path.join(current_dir, 'pages', 'map.html')
                with open(map_path, 'r', encoding='utf-8') as file:
                    return file.read()
            except FileNotFoundError:
                st.error(f"map.html íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
                st.error(f"ì‹œë„í•œ ê²½ë¡œ: {map_path}")
                return None

# HTML íŒŒì¼ ë¡œë“œ
html_content = load_html_file()

if html_content:
    # DXF ë°ì´í„°ê°€ ìˆìœ¼ë©´ JavaScript ë³€ìˆ˜ë¡œ ì£¼ì…
    if hasattr(st.session_state, 'dxf_data') and st.session_state.dxf_data:
        # JavaScript ì½”ë“œ ìƒì„±
        js_code = f"""
        <script>
        // DXF ë°ì´í„°ë¥¼ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •
        window.dxfData = {json.dumps(st.session_state.dxf_data)};
        console.log('DXF ë°ì´í„° ë¡œë“œë¨:', window.dxfData);
        </script>
        """
        
        # HTMLì— JavaScript ì½”ë“œ ì‚½ì…
        html_content = html_content.replace('</head>', js_code + '</head>')
    
    # HTMLì„ Streamlitì— í‘œì‹œ
    st.components.v1.html(
        html_content,
        height=800,
        scrolling=True
    )

    # ë°œíŒŒ ë°ì´í„° í™•ì¸ ì„¹ì…˜ ì¶”ê°€
    st.markdown("---")

    # ë°œíŒŒ ë°ì´í„° í™•ì¸ ì»¨í…Œì´ë„ˆ
    st.markdown("""
    <div style="
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        margin: 20px 0;
        border: 1px solid #e9ecef;
    ">
        <div style="
            display: flex;
            align-items: center;
            margin-bottom: 15px;
        ">
            <span style="
                font-size: 24px;
                margin-right: 10px;
            ">ğŸ§¨</span>
            <span style="
                font-size: 18px;
                font-weight: bold;
                color: #1f77b4;
            ">2. ë°œíŒŒ ë°ì´í„° í™•ì¸</span>
        </div>
        <p style="
            color: #6c757d;
            margin: 0;
            font-size: 14px;
        ">ë°œíŒŒì‘ì—…ì¼ì§€ì™€ ê³„ì¸¡ê²°ê³¼ ë³´ê³ ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë°ì´í„°ë¥¼ ë³‘í•©í•˜ê³  ì •ì œí•©ë‹ˆë‹¤.</p>
    </div>
    """, unsafe_allow_html=True)

    # íŒŒì¼ ì—…ë¡œë“œ ë¼ë²¨
    st.markdown("**ë°œíŒŒì‘ì—…ì¼ì§€ ë° ê³„ì¸¡ê²°ê³¼ ë³´ê³ ì„œ (2ê°œ íŒŒì¼)**")

    # ë°œíŒŒ ë°ì´í„° ì²˜ë¦¬ ìƒíƒœ í™•ì¸
    if not st.session_state.blast_data_completed:
        # íŒŒì¼ ì—…ë¡œë“œ ì˜ì—­
        blast_files = st.file_uploader(
            "ë°œíŒŒì‘ì—…ì¼ì§€ ë° ê³„ì¸¡ê²°ê³¼ ë³´ê³ ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['pdf', 'xlsx', 'xls'],
            accept_multiple_files=True,
            key="blast_files"
        )

        if len(blast_files) == 2:
            with st.spinner('ğŸ¤– AIê°€ ë°œíŒŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                try:
                    # ë‘ íŒŒì¼ì˜ ë‚´ìš© ì¶”ì¶œ
                    blast_text = extract_file_content(blast_files[0])
                    daily_text = extract_file_content(blast_files[1])
                    
                    if blast_text and daily_text:
                        # AI í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì‹¤í–‰
                        prompt = BLAST_EXTRACTION_PROMPT + f"\n\n## ì…ë ¥ 1: ë°œíŒŒì‘ì—…ì¼ì§€_TSV\n{blast_text}\n\n## ì…ë ¥ 2: ê³„ì¸¡ì¼ì§€_TSV\n{daily_text}"
                        response_text = safe_generate_content(prompt)

                        if response_text:
                            # TSV ë°ì´í„° ì¶”ì¶œ ë° íŒŒì‹±
                            tsv_result = extract_tsv_from_response(response_text)
                            df = parse_tsv_to_dataframe(fix_tsv_field_count(tsv_result))
                            
                            if df is not None:
                                st.session_state.blast_dataframe = df
                                st.session_state.blast_data_completed = True
                                st.success("âœ… 2ë‹¨ê³„ ì™„ë£Œ: ë°œíŒŒ ë°ì´í„° ë¶„ì„ ì„±ê³µ!")
                                st.rerun()
                            else: 
                                st.error("AI ì‘ë‹µì—ì„œ ìœ íš¨í•œ TSVë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.error("AI ëª¨ë¸ ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    else: 
                        st.error("íŒŒì¼ ë‚´ìš© ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                except Exception as e: 
                    st.error(f"ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        elif len(blast_files) == 1:
            st.info("ğŸ“ ë‘ ë²ˆì§¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        elif len(blast_files) == 0:
            st.info("ğŸ“ ë°œíŒŒì‘ì—…ì¼ì§€ì™€ ê³„ì¸¡ê²°ê³¼ ë³´ê³ ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    else:
        # ë°œíŒŒ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœ
        st.success("âœ… 2ë‹¨ê³„ ì™„ë£Œ: ë°œíŒŒ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì²˜ë¦¬ëœ ë°ì´í„° í‘œì‹œ
        with st.expander("ğŸ“Š ì²˜ë¦¬ëœ ë°œíŒŒ ë°ì´í„° ë³´ê¸°", expanded=True):
            if st.session_state.blast_dataframe is not None:
                st.dataframe(st.session_state.blast_dataframe, use_container_width=True)
                
                # ë°ì´í„° í†µê³„ ì •ë³´
                st.markdown("**ğŸ“ˆ ë°ì´í„° í†µê³„**")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì´ ë°œíŒŒ íšŸìˆ˜", len(st.session_state.blast_dataframe))
                with col2:
                    if 'í­ì•½ì‚¬ìš©ëŸ‰(kg)' in st.session_state.blast_dataframe.columns:
                        total_explosive = st.session_state.blast_dataframe['í­ì•½ì‚¬ìš©ëŸ‰(kg)'].sum()
                        st.metric("ì´ í­ì•½ ì‚¬ìš©ëŸ‰", f"{total_explosive:.1f} kg")
                with col3:
                    if 'ë°œíŒŒì§„ë™(cm/sec)' in st.session_state.blast_dataframe.columns:
                        max_vibration = st.session_state.blast_dataframe['ë°œíŒŒì§„ë™(cm/sec)'].max()
                        st.metric("ìµœëŒ€ ì§„ë™", f"{max_vibration:.2f} cm/sec")
        
        # ë°ì´í„° ì¬ì²˜ë¦¬ ë²„íŠ¼
        if st.button("ğŸ”„ ë°ì´í„° ì¬ì²˜ë¦¬"):
            st.session_state.blast_data_completed = False
            st.session_state.blast_dataframe = None
            st.rerun()

else:
    st.error("HTML íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")